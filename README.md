# ğŸ“„ AI-Powered Resume Screening System

An intelligent machine learning system that automatically analyzes and ranks candidate resumes based on job description requirements. Built with Python, scikit-learn, and Streamlit.

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3.2-orange.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28.0-red.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [ML Approach](#ml-approach)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Usage](#usage)
- [Sample Data](#sample-data)
- [How It Works](#how-it-works)
- [Technical Details](#technical-details)
- [Screenshots](#screenshots)
- [Contributing](#contributing)
- [License](#license)

## ğŸ¯ Overview

The AI-Powered Resume Screening System is designed to help HR professionals and recruiters efficiently screen large volumes of resumes. Using Natural Language Processing (NLP) and machine learning techniques, the system automatically matches candidate resumes with job descriptions and provides a ranked list of the best matches.

**Key Benefits:**
- âœ… Reduces manual resume screening time by up to 80%
- âœ… Provides objective, data-driven candidate rankings
- âœ… Automatically extracts and matches key qualifications
- âœ… Supports multiple file formats (PDF, TXT)
- âœ… Easy-to-use web interface
- âœ… Exportable results for further analysis

## âœ¨ Features

### Core Functionality
1. **Multi-Resume Upload**: Upload multiple resumes (PDF or TXT format) at once
2. **Job Description Input**: Enter detailed job requirements and qualifications
3. **ML-Powered Matching**: Automatic analysis using TF-IDF and cosine similarity
4. **Candidate Ranking**: Candidates ranked by match score (0-100%)
5. **Skills Matching**: Highlights matched keywords and skills
6. **Results Dashboard**: Visual representation of top candidates
7. **CSV Export**: Download results for sharing and further analysis

### User Interface
- Clean, professional Streamlit-based web interface
- Real-time processing with progress indicators
- Color-coded scoring (green/yellow/red)
- Top candidates highlighted with medal icons (ğŸ¥‡ğŸ¥ˆğŸ¥‰)
- Responsive design for different screen sizes

## ğŸ§  ML Approach

The system uses a straightforward but effective machine learning approach:

### 1. Text Preprocessing
```
Raw Text â†’ Lowercase â†’ Remove Special Characters â†’ Tokenization â†’ Remove Stopwords â†’ Clean Text
```

### 2. Feature Extraction (TF-IDF)
**TF-IDF (Term Frequency-Inverse Document Frequency)** converts text documents into numerical vectors:
- **Term Frequency (TF)**: How often a word appears in a document
- **Inverse Document Frequency (IDF)**: How unique/important a word is across all documents
- **Formula**: `TF-IDF(word, doc) = TF(word, doc) Ã— IDF(word)`

### 3. Similarity Scoring (Cosine Similarity)
**Cosine Similarity** measures the similarity between two vectors:
- Computes the cosine of the angle between job description and resume vectors
- **Range**: 0 (completely dissimilar) to 1 (identical)
- **Formula**: `cosine_similarity(A, B) = (A Â· B) / (||A|| Ã— ||B||)`

### 4. Ranking Algorithm
1. Compute similarity score for each resume
2. Convert to percentage (0-100%)
3. Sort candidates in descending order
4. Extract matching keywords
5. Return ranked results

## ğŸ“ Project Structure

```
ML-Project/
â”‚
â”œâ”€â”€ app.py                          # Streamlit web application
â”œâ”€â”€ resume_screener.py              # Core ML engine
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ product_specification.txt       # Detailed product specs
â”œâ”€â”€ README.md                       # This file
â”‚
â”œâ”€â”€ sample_data/                    # Sample files for testing
â”‚   â”œâ”€â”€ resume_1_john_anderson.txt
â”‚   â”œâ”€â”€ resume_2_sarah_martinez.txt
â”‚   â”œâ”€â”€ resume_3_michael_chen.txt
â”‚   â”œâ”€â”€ resume_4_emily_johnson.txt
â”‚   â”œâ”€â”€ resume_5_david_thompson.txt
â”‚   â””â”€â”€ job_description_ml_engineer.txt
â”‚
â””â”€â”€ .gitignore                      # Git ignore file
```

## ğŸš€ Installation

### Prerequisites
- Python 3.8 or higher
- pip (Python package manager)

### Step-by-Step Installation

1. **Clone the repository**
```bash
git clone https://github.com/Kris2k5/ML-Project.git
cd ML-Project
```

2. **Create a virtual environment (recommended)**
```bash
# On Windows
python -m venv venv
venv\Scripts\activate

# On macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Download NLTK data (automatic on first run)**
The application will automatically download required NLTK data on first run. If you want to download manually:
```python
import nltk
nltk.download('punkt')
nltk.download('stopwords')
```

## ğŸ’» Usage

### Running the Application

1. **Start the Streamlit app**
```bash
streamlit run app.py
```

2. **Open your browser**
The application will automatically open in your default browser at `http://localhost:8501`

### Using the Application

**Step 1: Upload Resumes**
- Click on the file uploader
- Select one or more resume files (PDF or TXT)
- Confirm files are uploaded successfully

**Step 2: Enter Job Description**
- Paste or type the job description in the text area
- Include required skills, qualifications, and experience
- Make sure it's detailed (at least 50 characters)

**Step 3: Analyze Candidates**
- Click the "ğŸš€ Analyze Candidates" button
- Wait for processing (usually a few seconds)
- View the results dashboard

**Step 4: Review Results**
- Check summary statistics
- Review ranked candidates
- Examine matched skills and keywords
- Download results as CSV if needed

### Command Line Usage (Optional)

You can also use the core ML engine programmatically:

```python
from resume_screener import ResumeScreener

# Initialize screener
screener = ResumeScreener()

# Define job description
job_desc = "Looking for Python developer with ML experience..."

# Define resume files
resumes = [
    ('candidate1.pdf', 'path/to/candidate1.pdf'),
    ('candidate2.txt', 'path/to/candidate2.txt')
]

# Analyze
results = screener.analyze_resumes(job_desc, resumes)
print(results)

# Export results
screener.export_results(results, 'results.csv')
```

## ğŸ“Š Sample Data

The `sample_data/` directory contains realistic test files:

**Resumes (5 candidates):**
1. `resume_1_john_anderson.txt` - Senior Software Engineer (Python, ML, TensorFlow)
2. `resume_2_sarah_martinez.txt` - Data Scientist (Python, scikit-learn, NLP)
3. `resume_3_michael_chen.txt` - Full Stack Developer (JavaScript, React, Node.js)
4. `resume_4_emily_johnson.txt` - Python/DevOps Engineer (Python, AWS, Docker)
5. `resume_5_david_thompson.txt` - Junior Software Engineer (Fresh graduate)

**Job Description:**
- `job_description_ml_engineer.txt` - Senior Machine Learning Engineer position

### Testing with Sample Data

1. Start the application: `streamlit run app.py`
2. Upload all 5 sample resumes from `sample_data/`
3. Copy contents of `job_description_ml_engineer.txt` into the job description field
4. Click "Analyze Candidates"
5. View the ranked results

**Expected Results:**
- John Anderson and Sarah Martinez should rank highest (strong ML/Python background)
- Emily Johnson should rank well (Python experience)
- Michael Chen should rank lower (different tech stack)
- David Thompson should rank lowest (junior, limited experience)

## ğŸ” How It Works

### Processing Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    1. INPUT STAGE                           â”‚
â”‚  Job Description + Multiple Resumes (PDF/TXT)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                2. TEXT EXTRACTION                           â”‚
â”‚  - PDF: PyPDF2 library                                      â”‚
â”‚  - TXT: Direct file reading                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                3. PREPROCESSING                             â”‚
â”‚  - Lowercase conversion                                     â”‚
â”‚  - Special character removal                                â”‚
â”‚  - Tokenization (NLTK)                                      â”‚
â”‚  - Stopword removal                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           4. FEATURE EXTRACTION (TF-IDF)                    â”‚
â”‚  - Vectorization using scikit-learn                         â”‚
â”‚  - Create numerical representations                         â”‚
â”‚  - Job description vector + Resume vectors                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          5. SIMILARITY COMPUTATION                          â”‚
â”‚  - Cosine similarity between job desc and each resume       â”‚
â”‚  - Score range: 0.0 to 1.0                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               6. RANKING & OUTPUT                           â”‚
â”‚  - Convert scores to percentages                            â”‚
â”‚  - Sort candidates by score                                 â”‚
â”‚  - Extract matching keywords                                â”‚
â”‚  - Generate results dataframe                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              7. DISPLAY RESULTS                             â”‚
â”‚  - Visual dashboard with rankings                           â”‚
â”‚  - Score indicators and matched skills                      â”‚
â”‚  - Export option                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Technical Details

### Technologies Used

**Core Libraries:**
- **Streamlit (1.28.0)**: Web application framework
- **scikit-learn (1.3.2)**: ML algorithms (TF-IDF, cosine similarity)
- **pandas (2.1.3)**: Data manipulation and analysis
- **NumPy (1.26.2)**: Numerical computations
- **PyPDF2 (3.0.1)**: PDF text extraction
- **NLTK (3.8.1)**: Natural language processing

### Key Components

**1. ResumeScreener Class (`resume_screener.py`)**
- `extract_text()`: Extracts text from PDF/TXT files
- `preprocess_text()`: Cleans and normalizes text
- `extract_keywords()`: Identifies important terms
- `analyze_resumes()`: Main analysis pipeline
- `export_results()`: CSV export functionality

**2. Streamlit UI (`app.py`)**
- File upload component
- Text input for job description
- Results visualization
- Download functionality
- Session state management

### Performance Metrics

**Processing Speed:**
- 10 resumes: ~3-5 seconds
- 50 resumes: ~10-15 seconds
- 100 resumes: ~25-30 seconds

**Accuracy Considerations:**
- Match scores are relative (not absolute)
- Works best with detailed job descriptions
- Better results with consistent terminology
- May miss context-specific qualifications

### Limitations

- Does not parse structured resume data (dates, education)
- Cannot understand context beyond keyword matching
- Scoring is relative, not absolute
- May not capture soft skills effectively
- Requires well-written job descriptions for best results

## ğŸ“¸ Screenshots

### Main Interface
*(Upload resumes and enter job description)*

### Results Dashboard
*(View ranked candidates with scores and matched skills)*

### Export Functionality
*(Download results as CSV)*

## ğŸ“ Educational Value

This project demonstrates:
1. **NLP Fundamentals**: Text preprocessing, tokenization, stopword removal
2. **Feature Engineering**: TF-IDF vectorization
3. **ML Algorithms**: Cosine similarity for text matching
4. **Python Best Practices**: Clean code, documentation, modularity
5. **Full-Stack Development**: Backend ML + Frontend UI
6. **Data Science Workflow**: From raw data to actionable insights

Perfect for:
- Academic presentations (soutenance)
- Portfolio projects
- Learning ML fundamentals
- Understanding NLP applications

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

**Areas for improvement:**
- Add support for DOCX files
- Implement deep learning models (BERT, transformers)
- Add resume parsing for structured data
- Create API endpoints for integration
- Add multi-language support
- Improve UI/UX design

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ‘¨â€ğŸ’» Author

**Kris2k5**
- GitHub: [@Kris2k5](https://github.com/Kris2k5)

## ğŸ™ Acknowledgments

- scikit-learn for ML algorithms
- Streamlit for the amazing web framework
- NLTK for NLP tools
- PyPDF2 for PDF processing
- The open-source community

## ğŸ“§ Contact

For questions or feedback, please open an issue on GitHub.

---

**â­ If you find this project helpful, please give it a star!**

---

## ğŸ”œ Future Enhancements

- [ ] Deep learning-based matching (BERT embeddings)
- [ ] Resume parsing for structured data extraction
- [ ] Database storage for historical analysis
- [ ] Advanced analytics and reporting
- [ ] Interview scheduling integration
- [ ] Multi-language support
- [ ] API for third-party integrations
- [ ] Custom ML model training

---

*Built with â¤ï¸ using Python, scikit-learn, and Streamlit*
